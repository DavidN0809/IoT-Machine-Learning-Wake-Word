{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f98bbad",
   "metadata": {},
   "source": [
    "# Audio Capture & Augmentation\n",
    "#### Author: Jeromey Schwartz\n",
    "#### *Audio capture code (indicated with *) supplied by Dr. Jeremy Holleman UNC-Charlotte "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e85322b",
   "metadata": {},
   "source": [
    "### Purpose:\n",
    "This will record an audio sample 1 second long at a sampling rate of 16kHz, the samples can then be augmented by adding noise, pitch shifting, or time shifting "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d0398a4",
   "metadata": {},
   "source": [
    "### Program Flow:\n",
    "1. Load libraries/setup code \n",
    "2. Save a number of audio samples \n",
    "3. Save ambient noise samples \n",
    "4. Noise shift \n",
    "5. Time shift \n",
    "6. Pitch shift \n",
    "7. Save samples names in validation document "
   ]
  },
  {
   "cell_type": "raw",
   "id": "dd7b44af",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4914f189",
   "metadata": {},
   "source": [
    "#### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a0c1da4",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'librosa'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 26\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmath\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtime\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mlibrosa\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'librosa'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.lite.experimental.microfrontend.python.ops import audio_microfrontend_op as frontend_op\n",
    "import numpy as np\n",
    "import time\n",
    "from scipy.io import wavfile\n",
    "import random\n",
    "import sys\n",
    "import io\n",
    "import os\n",
    "import pathlib\n",
    "import glob\n",
    "from datetime import datetime as dt\n",
    "from numpy import log as ln\n",
    "import matplotlib.mlab as mlab\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io.wavfile import write\n",
    "import IPython\n",
    "import IPython.display as ipd\n",
    "import tensorflow as tf\n",
    "%matplotlib inline\n",
    "import pyaudio\n",
    "from queue import Queue\n",
    "from threading import Thread\n",
    "import math\n",
    "import time\n",
    "import librosa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d93e449",
   "metadata": {},
   "source": [
    "#### Set Parameters*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e632d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "i16min            = -32768\n",
    "i16max            = 32767\n",
    "fsamp             = 16000\n",
    "wave_length_ms    = 1000\n",
    "wave_length_samps = 16000\n",
    "window_size_ms    = 60\n",
    "window_step_ms    = 40\n",
    "num_filters       = 32\n",
    "use_microfrontend = True\n",
    "keyword        = 'armadillo'#####Insert your keyword\n",
    "spectrogram_shape = (64, 24, 32, 1)\n",
    "\n",
    "chunk_duration = 0.25 # Each read length in seconds from mic.\n",
    "fs = 16000 # sampling rate for mic\n",
    "sample_rate = 16000 # sampling rate for mic\n",
    "chunk_samples = int(fs * chunk_duration) # Each read length in number of samples.\n",
    "\n",
    "# Each model input data duration in seconds, need to be an integer numbers of chunk_duration\n",
    "feed_duration = 1.0\n",
    "feed_samples = int(fs * feed_duration)\n",
    "\n",
    "assert feed_duration/chunk_duration == int(feed_duration/chunk_duration)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b6456e",
   "metadata": {},
   "source": [
    "#### Create keyword & noise folders*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc70430f",
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_dir = os.getcwd() #gets current directory\n",
    "folder_pre = \"Augmented_\" \n",
    "folder = folder_pre + keyword #name of directory\n",
    "dir = os.path.join(parent_dir,folder)\n",
    "noise_dir=os.path.join(parent_dir,\"noise\")\n",
    "#os.mkdir(dir) #creating folder\n",
    "#os.mkdir(noise_dir) #creating folder\n",
    "keyword_directory=dir + '\\\\'   \n",
    "print(\"Directory '% s' created\" % folder)\n",
    "print(\"Directory 'noise' created\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6ad7d1d9",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "d2691401",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "45d33f91",
   "metadata": {},
   "source": [
    "# Get Custom Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7cc895e",
   "metadata": {},
   "source": [
    "#### Run this code to get in an audio sample*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3288e6ce",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Queue to communiate between the audio callback and main thread\n",
    "q = Queue()\n",
    "run = True\n",
    "silence_threshold = 100\n",
    "# Run the demo for a timeout seconds\n",
    "timeout = time.time() + 1 \n",
    "# Data buffer for the input wavform\n",
    "data = np.zeros(feed_samples, dtype='int16')\n",
    "\n",
    "def callback(in_data, frame_count, time_info, status):\n",
    "    global run, timeout, data, silence_threshold    \n",
    "    if time.time() > timeout:\n",
    "        run = False        \n",
    "    data0 = np.frombuffer(in_data, dtype='int16')\n",
    "    data = np.append(data,data0)    \n",
    "    if len(data) > feed_samples:\n",
    "        data = data[-feed_samples:]\n",
    "        # Process data async by sending a queue.\n",
    "        q.put(data)\n",
    "    return (in_data, pyaudio.paContinue)\n",
    "\n",
    "stream = pyaudio.PyAudio().open(\n",
    "    format=pyaudio.paInt16,\n",
    "    channels=1,\n",
    "    rate=fs,\n",
    "    input=True,\n",
    "    frames_per_buffer=chunk_samples,\n",
    "    input_device_index=0,\n",
    "    stream_callback=callback)\n",
    "stream.start_stream()\n",
    "try:\n",
    "    while run:        \n",
    "        data = q.get()\n",
    "except (KeyboardInterrupt, SystemExit):\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    timeout = time.time()\n",
    "    run = False      \n",
    "stream.stop_stream()\n",
    "stream.close()\n",
    "\n",
    "sample_rate = fs\n",
    "\n",
    "\n",
    "#Displaying wave file data\n",
    "plt.plot(np.arange(1*fs)/fs, data)\n",
    "plt.show()\n",
    "ipd.Audio(data, rate=fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b5ac719",
   "metadata": {},
   "source": [
    "#### If the Sample looks good run cell below to save it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802139e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #saving the wave file to training_data\n",
    "date_str = dt.now().strftime(\"%H%M%S\").lower()\n",
    "current_name = f\"{keyword_directory}{keyword}_{date_str}.wav\"\n",
    "write(current_name, sample_rate, data)\n",
    "print(\"Audio sample saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c32de0a5",
   "metadata": {},
   "source": [
    "#### Noise\n",
    "* To get noise data run \"get data\" loop again to get ambient room\n",
    "* Save here\n",
    "* Get ~3 samples total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a496c94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #saving the wave file to training_data\n",
    "date_str = dt.now().strftime(\"%H%M%S\").lower()\n",
    "current_name = f\"{parent_dir}/noise/noise_{date_str}.wav\"\n",
    "write(current_name, sample_rate, data)\n",
    "print(\"Audio sample saved as noise\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "22fc0d2a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "f85df33c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9b8c59cc",
   "metadata": {},
   "source": [
    "# Audio Augmentation- Noise\n",
    "    * This will create copies of sample audio and add pre-recorded noise. \n",
    "    * The amplitude of the noise depends on *noise_count*\n",
    "    * Audio samples and visualizations are created to show noise augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7813e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Selecting augmentation folder & files\n",
    "data_dir = dir\n",
    "filenames = tf.io.gfile.glob(str(data_dir) + '/*.wav')\n",
    "\n",
    "#Testing if audio data imported correctly\n",
    "test_wav=filenames[0]\n",
    "fs, test_wav = wavfile.read(test_wav)\n",
    "plt.plot(np.arange(1*fs)/fs, test_wav)\n",
    "plt.show()\n",
    "ipd.Audio(test_wav, rate=fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e36dfc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading noise samples\n",
    "noise_dir = parent_dir+'\\\\noise'\n",
    "noise_samples = tf.io.gfile.glob(str(noise_dir) + '/*.wav')\n",
    "print(\"Noise Samples:\", len(noise_samples))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ca02bd",
   "metadata": {},
   "source": [
    "#### Set Augment count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b00e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "#noise_count will deteremine how many augmentations will be created\n",
    "    #noise_count=1 will be a copy with noise augmentation * 0\n",
    "    #noise_count=2 will be noise_count=1 plus a copy with noise augmentation * 1\n",
    "    #noise_count=2 will be noise_count=2 plus a copy with noise augmentation * 2  \n",
    "    #and so on \n",
    "\n",
    "noise_count=4\n",
    "print(\"This will expand the current\", len(filenames), \"files by creating an addtional\",len(filenames)*len(noise_samples)*noise_count, \"noise augmented files, to give a total of\",len(filenames)*len(noise_samples)*(noise_count)+len(filenames),\"files\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a67c2c",
   "metadata": {},
   "source": [
    "#### Creating Noise Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a7439dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dict holds samples for plotting\n",
    "noise_dict={}\n",
    "for index in range(len(filenames)):\n",
    "    test_wav=filenames[index]\n",
    "    fs, test_wav = wavfile.read(test_wav)\n",
    "    if (len(test_wav) < fs):\n",
    "        padding=fs-len(test_wav)\n",
    "        extra_padding=np.zeros(padding).astype(np.int16) #array of empty audio to pad with\n",
    "        test_wav=np.concatenate((test_wav,extra_padding),axis=0).astype(np.int16)\n",
    "    noise_dict[0]=test_wav.astype(np.int16)\n",
    "    for i in range(len(noise_samples)):\n",
    "        noise=noise_samples[i]\n",
    "        fs, noise = wavfile.read(noise)\n",
    "        for j in range(noise_count):\n",
    "            noise_multiplier=round(max(test_wav)*(j/2000))\n",
    "            noise_lvl=noise*noise_multiplier\n",
    "            test_wave_with_noise=np.add(test_wav,noise_lvl)\n",
    "            current_name = str(keyword_directory) + str(keyword)+f\"_Sample{index}_Noise{i}_Multiplier{j}.wav\"\n",
    "            write(current_name, fs, test_wave_with_noise)\n",
    "            noise_dict[j+1]=test_wave_with_noise.astype(np.int16)\n",
    "            noise_dict[j+5]=noise_lvl.astype(np.int16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b98b9b33",
   "metadata": {},
   "source": [
    "#### Plotting noise augmenation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ce4418",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Only plots up to noise lvl 3\n",
    "fig, axs = plt.subplots(4, 4,figsize=(20,10), sharex=True,sharey=True)\n",
    "axs[0,0].plot(np.arange(1*fs)/fs, noise_dict[0])\n",
    "axs[0,1].plot(np.arange(1*fs)/fs, noise_dict[5], 'tab:orange')\n",
    "axs[0,2].plot(np.arange(1*fs)/fs, noise_dict[0])\n",
    "axs[0,2].plot(np.arange(1*fs)/fs, noise_dict[5])\n",
    "axs[0,3].plot(np.arange(1*fs)/fs, noise_dict[1])\n",
    "\n",
    "axs[0, 0].set_title(\"Original\")\n",
    "axs[0, 1].set_title(\"Noise\")\n",
    "axs[0, 2].set_title(\"Original + Noise\")\n",
    "axs[0, 3].set_title(\"Augmented Audio\")\n",
    "\n",
    "axs[0, 0].set(xlabel='Time (s)', ylabel='Noise lvl 0')\n",
    "axs[1, 0].set(xlabel='Time (s)', ylabel='Noise lvl 1')\n",
    "axs[2, 0].set(xlabel='Time (s)', ylabel='Noise lvl 2')\n",
    "axs[3, 0].set(xlabel='Time (s)', ylabel='Noise lvl 3')\n",
    "\n",
    "axs[1,0].plot(np.arange(1*fs)/fs, noise_dict[0])\n",
    "axs[1,1].plot(np.arange(1*fs)/fs, noise_dict[6], 'tab:orange')\n",
    "axs[1,2].plot(np.arange(1*fs)/fs, noise_dict[0])\n",
    "axs[1,2].plot(np.arange(1*fs)/fs, noise_dict[6])\n",
    "axs[1,3].plot(np.arange(1*fs)/fs, noise_dict[2])\n",
    "\n",
    "axs[2,0].plot(np.arange(1*fs)/fs, noise_dict[0])\n",
    "axs[2,1].plot(np.arange(1*fs)/fs, noise_dict[7], 'tab:orange')\n",
    "axs[2,2].plot(np.arange(1*fs)/fs, noise_dict[0])\n",
    "axs[2,2].plot(np.arange(1*fs)/fs, noise_dict[7])\n",
    "axs[2,3].plot(np.arange(1*fs)/fs, noise_dict[3])\n",
    "\n",
    "axs[3,0].plot(np.arange(1*fs)/fs, noise_dict[0])\n",
    "axs[3,1].plot(np.arange(1*fs)/fs, noise_dict[8], 'tab:orange')\n",
    "axs[3,2].plot(np.arange(1*fs)/fs, noise_dict[0])\n",
    "axs[3,2].plot(np.arange(1*fs)/fs, noise_dict[8])\n",
    "axs[3,3].plot(np.arange(1*fs)/fs, noise_dict[4])\n",
    "\n",
    "for ax in axs.flat:\n",
    "    ax.set(xlabel='Time (s)')\n",
    "\n",
    "# Hide x labels and tick labels for top plots and y ticks for right plots.\n",
    "for ax in axs.flat:\n",
    "    ax.label_outer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f85f4855",
   "metadata": {},
   "source": [
    "#### Listen to noise augmenation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c692f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Only samples up to noise lvl 3\n",
    "from IPython.display import Audio \n",
    "from IPython.display import display\n",
    "\n",
    "print(\"Noise lvl 0:\")\n",
    "display(Audio(noise_dict[0], rate=fs))\n",
    "print(\"Noise lvl 1:\")\n",
    "display(Audio(noise_dict[2], rate=fs))\n",
    "print(\"Noise lvl 2:\")\n",
    "display(Audio(noise_dict[3], rate=fs))\n",
    "print(\"Noise lvl 3:\")\n",
    "display(Audio(noise_dict[4], rate=fs))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "87ac19ac",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "84c5fac5",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2290394e",
   "metadata": {},
   "source": [
    "# Audio Augmentation- Time Shift\n",
    "    * This will create copies of sample audio and shift them forward or backward in time in 1/8s increments \n",
    "    * The \"empty space\" created by the time shift is filled with artificial noise (created in cell 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bcb05e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Need to update filenames\n",
    "data_dir = dir\n",
    "filenames = tf.io.gfile.glob(str(data_dir) + '/*.wav')\n",
    "#Testing if audio data imported correctly\n",
    "filenames[0]\n",
    "test_wav=filenames[0]\n",
    "fs, test_wav = wavfile.read(test_wav)\n",
    "plt.plot(np.arange(1*fs)/fs, test_wav)\n",
    "plt.show()\n",
    "ipd.Audio(test_wav, rate=fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dccb71b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initializing variables for 1/8th second time shifts\n",
    "one_eighth=int((sample_rate/8)) #16k sample rate means 2k for 1/8s\n",
    "padding=one_eighth #Number of samples to pad\n",
    "#zero_padding=np.zeros(padding).astype(np.int16) #array of empty audio to pad with\n",
    "noise_lvl_min=-200 #about the min for quiet room when measured with get audio code above\n",
    "noise_lvl_max=200 #about the max for quiet room when measured with get audio code above\n",
    "noise_padding=np.random.randint(noise_lvl_min,noise_lvl_max+1,padding) #makes random noise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b271b2a",
   "metadata": {},
   "source": [
    "#### Set Augment count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ee063e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#how many of each type of time shift is desired..in 1/8s increments\n",
    "#suggest following bell curve with center being zero_shift and left_3/right_3 being the extremes\n",
    "\n",
    "left_3=1\n",
    "left_2=2\n",
    "left_1=2\n",
    "zero_shift=2\n",
    "right_1=2\n",
    "right_2=2\n",
    "right_3=1\n",
    "\n",
    "total=zero_shift+right_3+right_2+right_1+left_3+left_2+left_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77bf71ab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"This will expand the current\", len(filenames), \"files by creating an addtional\",len(filenames)*total, \"time shifted files, to give a total of\",len(filenames)*(total+1),\"files\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfdc3cbe",
   "metadata": {},
   "source": [
    "#### Time Shift Augment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a648746",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creates dictionary to hold audio for data visualization\n",
    "audio_dict={}\n",
    "\n",
    "##This will randomize audio samples\n",
    "#random_list = list(range(0, len(filenames))) #create array [1,2,3...]\n",
    "#random.shuffle(random_list) #randomize the array\n",
    "\n",
    "#This will reverse the list so the element printed in next cell shows augmentation to original sample\n",
    "random_list = list(range(0, len(filenames))) #create array [1,2,3...]\n",
    "random_list.reverse() #randomize the array\n",
    "\n",
    "#runs 5x shifts audio from original to left by .5sec in 1/8s increments\n",
    "for index in range(len(filenames)):\n",
    "    test_wav=filenames[random_list[index]]\n",
    "    fs, test_wav = wavfile.read(test_wav)\n",
    "    audio_dict[0]=test_wav.astype(np.int16)#dict[0] holds original audio\n",
    "    test_wav_decrease = test_wav #creating copy to be manipulated \n",
    "    test_wav_increase = test_wav #creating copy to be manipulated\n",
    "    \n",
    "    #shift audio to left in 1/8s increments\n",
    "    for j in range(1,4):#dict 1-4 hold shifted audio (change 4 to 5 to make 1/2s shift)\n",
    "        for i in range (one_eighth):\n",
    "            test_wav_decrease=np.delete(test_wav_decrease,0)\n",
    "        test_wav_decrease=np.concatenate((test_wav_decrease,noise_padding),axis=0).astype(np.int16)\n",
    "        audio_dict[j]=test_wav_decrease.astype(np.int16)\n",
    "        if (j==1):\n",
    "            for p in range(left_1): #creates left_1 copys shifted left 1/8s\n",
    "                current_name = str(keyword_directory) + str(keyword)+f\"_Sample{index}_LShift{j}_{p}.wav\"\n",
    "                write(current_name, fs, test_wav_decrease)\n",
    "        if (j==2):\n",
    "            for p in range(left_2): #creates left_2 copys shifted left 2/8s\n",
    "                current_name = str(keyword_directory) + str(keyword)+f\"_Sample{index}_LShift{j}_{p}.wav\"\n",
    "                write(current_name, fs, test_wav_decrease)\n",
    "        if (j==3):\n",
    "            for p in range(left_3): #creates left_3 copy shifted left 3/8s\n",
    "                current_name = str(keyword_directory) + str(keyword)+f\"_Sample{index}_LShift{j}_{p}.wav\"\n",
    "                write(current_name, fs, test_wav_decrease)\n",
    "\n",
    "    \n",
    "    #shift audio to right in 1/8s increments\n",
    "    for k in range(6,9):\n",
    "        #pad zeros to front\n",
    "        test_wav_increase=np.concatenate((noise_padding,test_wav_increase),axis=0)\n",
    "        #delete data past 16k samples\n",
    "        for d in range(sample_rate,len(test_wav_increase)):\n",
    "            test_wav_increase=np.delete(test_wav_increase,sample_rate,0).astype(np.int16)\n",
    "        audio_dict[k]=test_wav_increase\n",
    "        if (k==6):\n",
    "            for p in range(right_1): #creates right_1 copys shifted right 1/8s\n",
    "                current_name = str(keyword_directory) + str(keyword)+f\"_Sample{index}_RShift{k-5}_{p}.wav\"\n",
    "                write(current_name, fs, test_wav_decrease)\n",
    "        if (k==7):\n",
    "            for p in range(right_2): #creates right_2 copys shifted right 2/8s\n",
    "                current_name = str(keyword_directory) + str(keyword)+f\"_Sample{index}_RShift{k-5}_{p}.wav\"\n",
    "                write(current_name, fs, test_wav_decrease)\n",
    "        if (k==8):\n",
    "            for p in range(right_3): #creates right_3 copy shifted right 3/8s\n",
    "                current_name = str(keyword_directory) + str(keyword)+f\"_Sample{index}_RShift{k-5}_{p}.wav\"\n",
    "                write(current_name, fs, test_wav_decrease)\n",
    "    for l in range(zero_shift):\n",
    "        current_name = str(keyword_directory) + str(keyword)+f\"_Sample{index}_NoShift_{l}.wav\"\n",
    "        write(current_name, fs, test_wav)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b47f189",
   "metadata": {},
   "source": [
    "#### Plot time shifted audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175891fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#commented out is for half second shift if desired\n",
    "\n",
    "fig = plt.figure(constrained_layout=True)\n",
    "axs = fig.add_gridspec(3, 3)\n",
    "\n",
    "f_ax0 = fig.add_subplot(axs[0, 1])\n",
    "f_ax1 = fig.add_subplot(axs[1, 0])\n",
    "f_ax2 = fig.add_subplot(axs[1, 1])\n",
    "f_ax3 = fig.add_subplot(axs[1, 2])\n",
    "# f_ax4 = fig.add_subplot(axs[2, 3])\n",
    "f_ax6 = fig.add_subplot(axs[2, 0])\n",
    "f_ax7 = fig.add_subplot(axs[2, 1])\n",
    "f_ax8 = fig.add_subplot(axs[2, 2])\n",
    "# f_ax9 = fig.add_subplot(axs[3, 3])\n",
    "\n",
    "f_ax0.plot(np.arange(1*fs)/fs, audio_dict[0])\n",
    "f_ax1.plot(np.arange(1*fs)/fs, audio_dict[1])\n",
    "f_ax2.plot(np.arange(1*fs)/fs, audio_dict[2])\n",
    "f_ax3.plot(np.arange(1*fs)/fs, audio_dict[3])\n",
    "# f_ax4.plot(np.arange(1*fs)/fs, audio_dict[4])\n",
    "f_ax6.plot(np.arange(1*fs)/fs, audio_dict[6])\n",
    "f_ax7.plot(np.arange(1*fs)/fs, audio_dict[7])\n",
    "f_ax8.plot(np.arange(1*fs)/fs, audio_dict[8])\n",
    "# f_ax9.plot(np.arange(1*fs)/fs, audio_dict[9])\n",
    "\n",
    "f_ax0.set_title('Original')\n",
    "f_ax1.set_title('Shifted left 1/8')\n",
    "f_ax2.set_title('Shifted left 1/4')\n",
    "f_ax3.set_title('Shifted left 3/8')\n",
    "# f_ax4.set_title('Shifted left 1/2')\n",
    "f_ax6.set_title('Shifted right 1/8')\n",
    "f_ax7.set_title('Shifted right 1/4')\n",
    "f_ax8.set_title('Shifted right 3/8')\n",
    "# f_ax9.set_title('Shifted right 1/2')\n",
    "fig.set_size_inches(18.5, 10.5, forward=True)\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a5ec8e7",
   "metadata": {},
   "source": [
    "#### Listen to time shifted Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f81651",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Audio \n",
    "from IPython.display import display\n",
    "\n",
    "print(\"Original:\")\n",
    "display(Audio(audio_dict[0], rate=fs))\n",
    "print(\"Shifted left 1/8:\")\n",
    "display(Audio(audio_dict[1], rate=fs))\n",
    "print(\"Shifted left 1/4:\")\n",
    "display(Audio(audio_dict[2], rate=fs))\n",
    "print(\"Shifted left 3/8:\")\n",
    "display(Audio(audio_dict[3], rate=fs))\n",
    "# print(\"Shifted left 1/2:\")\n",
    "# display(Audio(audio_dict[4], rate=fs))\n",
    "print(\"Shifted right 1/8:\")\n",
    "display(Audio(audio_dict[6], rate=fs))\n",
    "print(\"Shifted right 1/4:\")\n",
    "display(Audio(audio_dict[7], rate=fs))\n",
    "print(\"Shifted right 3/8:\")\n",
    "display(Audio(audio_dict[8], rate=fs))\n",
    "# print(\"Shifted right 1/2:\")\n",
    "# display(Audio(audio_dict[9], rate=fs))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f79480e0",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "ffbb93cf",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8b2f40a1",
   "metadata": {},
   "source": [
    "# Audio Augmentation- Pitch Shift\n",
    "    * This will create copies of sample audio and pitch shift them\n",
    "    * The variable *pitch_shift* allows control over pitch\n",
    "    * The variable *desired_number_of_files* allows control of exactly how many samples to create\n",
    "    * The loop will continue creating copies until desired count is reached, including pitch shifting already pitch shifted copies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169e2afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Need to update filenames\n",
    "data_dir = dir\n",
    "filenames = tf.io.gfile.glob(str(data_dir) + '/*.wav')\n",
    "#Testing if audio data imported correctly\n",
    "filenames[0]\n",
    "test_wav=filenames[0]\n",
    "fs, test_wav = wavfile.read(test_wav)\n",
    "plt.plot(np.arange(1*fs)/fs, test_wav)\n",
    "plt.show()\n",
    "ipd.Audio(test_wav, rate=fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf0ab90",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The current number of files in directory is\", len(filenames))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee19898",
   "metadata": {},
   "source": [
    "#### Set Augment count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59406c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "#How many of the files do you want to have total?\n",
    "desired_number_of_files=100\n",
    "\n",
    "#How do you want to pitch shift\n",
    "    #positive=high pitch, negative = low pitch\n",
    "    #0.25 is a good value\n",
    "pitch_shift=0.25"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9a226b7f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "faa7c992",
   "metadata": {},
   "source": [
    "### Doubling Equation:   \n",
    "> $output=input * 2^{x}$\n",
    "\n",
    "*Here $x$ is the number of times input is doubled\n",
    "\n",
    "#### To get desired number of output files from input when loop doubles input every iteration of the for loop we solve for $x$:\n",
    "   \n",
    "> $x=\\log _{2}(\\frac{out}{in})$\\\n",
    "  $x=\\frac{\\ln (\\frac{out}{in})} {\\ln (2)}$\n",
    "                 \n",
    "#### Next $math.ceil()$ is used to round up to integer for loop iteration\n",
    "\n",
    "> $x=$ math.ceil$(\\frac{\\ln (out)}{\\ln (in)})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f888ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Doubling formula used to find range for outer for loop indexing with \"i\"\n",
    "outer_range= math.ceil((np.log(desired_number_of_files / len(filenames)) / np.log(2) ))\n",
    "outer_range"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d116a7",
   "metadata": {},
   "source": [
    "#### Pitch Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "909afc96",
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace line 11 with comment below if you want to create a custom # < len(filenames)...\n",
    "#                                                    ...comment out if statements and speed will improve significantly\n",
    "#for index in range(40000): \n",
    "\n",
    "pitch_dict={}\n",
    "for i in range(outer_range):\n",
    "    for index in range(len(filenames)):\n",
    "        test_wav=filenames[index]\n",
    "        fs, test_wav = wavfile.read(test_wav)\n",
    "        if i==0:\n",
    "            pitch_dict[i]=test_wav\n",
    "        test_wav_float=test_wav.astype(float)\n",
    "        test_wav_pitch_shifted = librosa.effects.pitch_shift(test_wav_float, sr=sample_rate, n_steps=pitch_shift*(i+1))\n",
    "        test_wav_pitch_shifted_int=test_wav_pitch_shifted.astype(np.int16)\n",
    "        current_name = str(keyword_directory)+str(keyword) +f\"_Pitch_Shift_{i}_{index}.wav\"    \n",
    "        write(current_name, fsamp, test_wav_pitch_shifted_int)\n",
    "\n",
    "        files_in_folder=len(tf.io.gfile.glob(str(data_dir) + '/*.wav'))\n",
    "        pitch_dict[i+1]=test_wav_pitch_shifted_int\n",
    "        if (files_in_folder >= desired_number_of_files):\n",
    "            break \n",
    "    filenames = tf.io.gfile.glob(str(data_dir) + '/*.wav')\n",
    "    #update filenames with newly created files    \n",
    "    if (files_in_folder >= desired_number_of_files):\n",
    "        break \n",
    "print(\"Congratulations, the current number of files in directory is\", len(filenames))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf4aea1e",
   "metadata": {},
   "source": [
    "#### Plot Pitch Shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eff61ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(constrained_layout=True)\n",
    "axs = fig.add_gridspec(3, 3)\n",
    "\n",
    "f_ax0 = fig.add_subplot(axs[0, 1])\n",
    "f_ax1 = fig.add_subplot(axs[1, 0])\n",
    "f_ax2 = fig.add_subplot(axs[1, 1])\n",
    "f_ax3 = fig.add_subplot(axs[1, 2])\n",
    "f_ax4 = fig.add_subplot(axs[2, 0])\n",
    "f_ax5 = fig.add_subplot(axs[2, 1])\n",
    "f_ax6 = fig.add_subplot(axs[2, 2])\n",
    "\n",
    "f_ax0.plot(np.arange(1*fs)/fs, pitch_dict[0])\n",
    "f_ax0.set_title('Original')\n",
    "\n",
    "if outer_range>1:\n",
    "    f_ax1.plot(np.arange(1*fs)/fs, pitch_dict[1])\n",
    "    f_ax1.set_title('Pitch Shift lvl 1')\n",
    "if outer_range>2:\n",
    "    f_ax2.plot(np.arange(1*fs)/fs, pitch_dict[2])\n",
    "    f_ax2.set_title('Pitch Shift lvl 2')\n",
    "if outer_range>3:\n",
    "    f_ax3.plot(np.arange(1*fs)/fs, pitch_dict[3])\n",
    "    f_ax3.set_title('Pitch Shift lvl 3')\n",
    "if outer_range>4:\n",
    "    f_ax4.plot(np.arange(1*fs)/fs, pitch_dict[4])\n",
    "    f_ax4.set_title('Pitch Shift lvl 4')\n",
    "if outer_range>5:\n",
    "    f_ax5.plot(np.arange(1*fs)/fs, pitch_dict[5])\n",
    "    f_ax5.set_title('Pitch Shift lvl 5')\n",
    "if outer_range>6:\n",
    "    f_ax6.plot(np.arange(1*fs)/fs, pitch_dict[6])\n",
    "    f_ax6.set_title('Pitch Shift lvl 6')\n",
    "\n",
    "fig.set_size_inches(18.5, 10.5, forward=True)\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba23c715",
   "metadata": {},
   "source": [
    "#### Listen to Pitch Shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb33348",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Audio \n",
    "from IPython.display import display\n",
    "\n",
    "print(\"Original:\")\n",
    "display(Audio(pitch_dict[0], rate=fs))\n",
    "\n",
    "if outer_range>1:\n",
    "    print(\"Pitch Shift lvl 1\")\n",
    "    display(Audio(pitch_dict[1], rate=fs))\n",
    "if outer_range>2:\n",
    "    print(\"Pitch Shift lvl 2\")\n",
    "    display(Audio(pitch_dict[2], rate=fs))\n",
    "if outer_range>3:\n",
    "    print(\"Pitch Shift lvl 3\")\n",
    "    display(Audio(pitch_dict[3], rate=fs))\n",
    "if outer_range>4:\n",
    "    print(\"Pitch Shift lvl 4\")\n",
    "    display(Audio(pitch_dict[3], rate=fs))\n",
    "if outer_range>5:\n",
    "    print(\"Pitch Shift lvl 5\")\n",
    "    display(Audio(pitch_dict[4], rate=fs))\n",
    "if outer_range>6:\n",
    "    print(\"Pitch Shift lvl 6\")\n",
    "    display(Audio(pitch_dict[5], rate=fs))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b37b90c1",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d490e2a9",
   "metadata": {},
   "source": [
    "# Write augmented data files to testing and validation .txt file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5ed844",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Need to update filenames\n",
    "data_dir = dir\n",
    "filenames = tf.io.gfile.glob(str(data_dir) + '/*.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b97fbb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Verifying opens files correctly\n",
    "filenames[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14699aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_files=len(filenames)\n",
    "num_files\n",
    "print(\"Total files:\", num_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802e4e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "#randomizes order of samples for validation list\n",
    "random_list = list(range(0, num_files)) #create array [1,2,3...]\n",
    "random.shuffle(random_list) #randomize the array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f497c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#will write to file in form: keyword_folder/audio_sample\n",
    "from pathlib import Path\n",
    "\n",
    "#Set directory for validation list\n",
    "dir_path = Path(os.getcwd()) #current directory\n",
    "\n",
    "file_name = 'validation_list.txt'\n",
    "\n",
    "#How many files to add to document?\n",
    "add_val_num=5\n",
    "\n",
    "# check if directory exists\n",
    "#copys over files to the validation document\n",
    "if dir_path.is_dir():\n",
    "    f = open (dir_path.joinpath(file_name),'a')\n",
    "    filenames = tf.io.gfile.glob(str(data_dir) + '/*.wav')\n",
    "    for i in range(add_val_num):\n",
    "        f.write('\\n'+keyword+'\\\\'+ os.path.basename(filenames[random_list[i]]))\n",
    "    f.close()\n",
    "    print(add_val_num, keyword, \"samples added to\", file_name)\n",
    "else:\n",
    "    print('Directory doesnt exist')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "eb42ff9d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ba2a3559",
   "metadata": {},
   "source": [
    "# Additional Augmentations\n",
    "    *These change volume\n",
    "    *Still needs work, suggest staying with previous augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8497a423",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "data_dir = dir\n",
    "filenames = tf.io.gfile.glob(str(data_dir) + '/*.wav')\n",
    "#Testing if audio data imported correctly\n",
    "test_wav=filenames[0]\n",
    "fs, test_wav = wavfile.read(test_wav)\n",
    "plt.plot(np.arange(1*fs)/fs, test_wav)\n",
    "plt.show()\n",
    "ipd.Audio(test_wav, rate=fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6ef568",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Sample count:\", len(filenames))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9163aaad",
   "metadata": {},
   "source": [
    "#### Icrease audio sample amplitude by multiplier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5aa6002",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Increases existing audios volume/amplitue \n",
    "multiplier=3\n",
    "for i in range(1,multiplier):\n",
    "    for index in range(len(filenames)):\n",
    "            test_wav=filenames[index]\n",
    "            fs, test_wav = wavfile.read(test_wav)\n",
    "            sound=test_wav*(i)\n",
    "            sound_normalized=sound.astype(np.int16)\n",
    "            current_name = str(keyword_directory) + str(keyword)+f\"noiseLVL_{i}_{index}.wav\" \n",
    "            write(current_name, fsamp, sound_normalized)\n",
    "\n",
    "data_dir = dir\n",
    "filenames = tf.io.gfile.glob(str(data_dir) + '/*.wav')\n",
    "print(\"Multiplier complete\")\n",
    "print(\"Sample count:\", len(filenames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba01f92e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa3ba5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_wav=filenames[250]\n",
    "fs, test_wav = wavfile.read(test_wav)\n",
    "plt.plot(np.arange(1*fs)/fs, test_wav)\n",
    "plt.show()\n",
    "ipd.Audio(test_wav, rate=fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "757f9062",
   "metadata": {},
   "source": [
    "#### Normalize to specific amplitude level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e682e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_level=12000\n",
    "for index in range(len(filenames)):\n",
    "        test_wav=filenames[index]\n",
    "        fs, test_wav = wavfile.read(test_wav)\n",
    "        sound = test_wav*(noise_level/max(test_wav))\n",
    "        sound_normalized=sound.astype(np.int16)\n",
    "        current_name = str(keyword_directory) + str(keyword)+f\"_{index}.wav\" \n",
    "        #current_name = filenames[index]\n",
    "        write(current_name, fsamp, sound_normalized)\n",
    "        if ((index%10)==0):\n",
    "            print(f\"{index}/{len(filenames)} complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e643c9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_wav=filenames[250]\n",
    "fs, test_wav = wavfile.read(test_wav)\n",
    "plt.plot(np.arange(1*fs)/fs, test_wav)\n",
    "plt.show()\n",
    "ipd.Audio(test_wav, rate=fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b86325",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
